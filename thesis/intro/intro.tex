%1. 31. Mai Einleitung, Motivation & Ziele, Strukturskizze der Arbeit
%(grob). => 4 Seiten
%Zusätzlich Skizze für DesignKapitel mit Stichpunkten (d.h. weiter
%ausführen von Kapitel 3., evtl. erste Bilder)

\section{Einleitung}
%%% Problematik %%%
% Problematik: Geschichtliche Entwicklung
In den letzten Jahren nahm die Leistungsfähigkeit der Hardware von Computersystemen zu: es erfolgte ein exponentieller Kapazitätswachstum des Massenspeichers, begleitet von einer vergleichsweise langsame Zunahme der Datenübertragungsgeschwindigkeiten, die Integrierung mehrerer Kerne in die Prozessoren und einen explosionsartigen Wachstum von Datenmengen.

Früher war die Erhöhung der Taktfrequenz die Hauptmethode die Prozessorleistung zu steigern. Nachdem aber die physikalischen Grenzen der Halbleiterkomponenten erreicht wurden und die Erhöhung der Taktfrequenz nicht mehr möglich war ist man dazu übergegangen Prozessoren mit mehreren Kernen zu auszustatten. Der Trend hält bis heute an und heute sind in meisten modernen Rechner Multikern-Prozessoren verbaut.

Die Fortschritte in der Massenspeicherentwicklung der letzten Jahre haben vor allem zur höheren Datendichte geführt, was die Herstellung von Geräten mit hoher Kapazität ermöglicht hat. Der Kapazitätswachstum, wie im Moore'schen Gesetz bereits formuliert, hat sich etwa alle anderethalb bis zwei Jahre verdoppelt bei gleichzeitig sinkendem Preis pro Speichereinheit.

Laut dem Bericht von IDC-Studie \cite{idc} verdoppelt sich auch das weltweite Datenvolumen alle zwei Jahre. Im Jahr 2013 wurde der Gesamtdatenvolumen auf etwas 4.4 Zetabyte geschätzt. Im Jahr 2020 soll dieser Wert auf 44 Zetabyte steigen. Die Datenproduktion wir von steigender Zahl der Geräte, wie digitale Kameras, mehr Leute produzieren Daten, es gibt immer mehr datenbasierte Dienste, wie Online-Data-Clouds.



\subsection{Problematik}
Die in der Vergangenheit unausbalancierte Entwicklung hat heute zu gewissen Problemen geführt.
% Problematik: E/A-Flaschenhals 
So sind die Massenspeichermedien und deren Anbindung oft die langsameren Komponenten in einem Computer und bilden unter bestimmten Bedingungen einen Flaschenhals, der sich negativ auf die Antwortzeiten, Datendurchsatz und Auslastung des Systems aufwirkt. 

Ganz besonders betroffen davon sind Hochleistungs-Computer und die Server, wenn darauf viele Benutzer gleichzeitig arbeiten oder wenn große Datenmenge verarbeit werden. Viele Benutzer können durch viele gleichzeitige E/A-Zugriffe, z.B. durch Lesen von einer Vielzahl von kleinen Dateien oder durch Ausführen von E/A-lastige Prozessen, schnell die Grenzen der Hardware ausreizen. Das führt zu höheren Systemreaktionszeiten, die von Benutzern als besonders störend empfunden wird. Bei Computern, die E/A-lastige Hintergrunddienste ausführen, macht sich das Problem durch geringen Systemauslastung bemerkbar. Die Ursache ist für beide Symptome gleich: die Prozessoren verbringen eine beträchtliche Zeit im Leerlauf, währen sie auf die Daten warten. 

% Problematik: Nutzung von IT-Systemen
In der Wirtschaft gibt es zwei große Bereiche, die auf hohe E/A-Leistung angewiesen sind. Das sind OLAP (Online Analytical Procesing) und OLTP (Online Transaction Processing). Im OLAP-Bereich nutzt man relativ große Datenbestände für die Informationsgewinnung. Die gewonnen Informationen sollen den Führungskräften und Managern bei den Entscheidungen helfen und deshalb liegt hier der Fokus auf den kurzen Reaktionszeiten. Im OLAP-Bereich hingegen geht es um die Datenspeicherung. Das Ziel ist die Daten im konsistenten Zustand zu behalten und die Transaktionenzahl zu maximieren.Diese beiden Bereiche sind wahrscheinlich von dem Problem am schlimmsten betroffen.

Es gibt zahlreiche weitere Bereiche, die nicht weniger stark von dem Problem betroffen sind, z.B. die Verarbeitung der Messdaten in der Klimaforschung, Datensicherung im Unternehmen, interaktiven Knoten, auch private Computer.

\subsection{Überblick über die Lösungsansätze}
%%% Techniken um die E/A-Leistung zu verbessern %%%
Die Systemhersteller, Systembetreiber und die Wissenschaftler bemühen sich das Problem\todo{eben waren es noch mehrere Probleme} mit verschiedenen Techniken in den Griff zu bekommen. 

% Raid
\todo{Parallele Dateisysteme auch hier erwähnen, RAID ist ein älterer Hut}
Viele Systeme, insbesondere Server und HPC-Systeme, sind mit Raid-Verbunden ausgestattet, wobei jedes Raid-Typ ein oder mehrere Ziele verfolgen kann. Die meisten Raid-Verbunde versuchen jedoch ein Kompromiss zwischen Leistung, Datensicherheit und Kosten zu finden, wobei die Ziele gegeneinander gerichtet sind, was bedeutet, dass man das eine nicht verbessern kann ohne das andere zu verschlechtern. Die relativ hohen Anschaffungs-, Betriebs- und Wartungskosten machen die Raid-Systeme nur bis zur einer gewissen Größe wirtschaftlich. Ausserdem erreichen die Raid-Verbunde eine höhere Leistung nur für Daten ab einer bestimmten Größe. Der Grund liegt in der Funktionsweise der Raid-Verbunde. Sie zerteilen die Daten in die s.g.\todo{Ausschreiben} Chuncks und schreiben diese Daten parallel auf mehrer Massenspeicherkomponeneten. Wenn die Daten nicht auf mehrere Chunks zerteilen lassen, dann kann keine paralleler Schreibzugriff stattfinden, deshalb auch kein Leistungsgewinn. Für den Lesezugriff gilt die analoge Logik.

% Cache
Die Caches eine weitere weitverbreitete Methode die E/A-Leistung zu verbessern. Dabei werden die oft genutzte oder voraussichtlich bald benötigte Daten auf einem schnelleren Datenträger zwischenzuspeichert, z.B. ist in den meisten modernen Internet-Browsern das HTTP-Caching implementiert. Die Inhalte der Webseiten werden auf der Festplatte abgelegt, um beim wiederholten Zugriff bereits besuchte Seiten schnell aufzubauen und unnötigen Datenverkehr zu vermeiden. 
OLTP-Datenbankenbetreiber (On-Line-Transaction Processing), bauen zusätzlich zu Festplattenverbunden SSD-Zwischenspeicher in Ihre Systeme ein, um die Transaktionenanzahl zu erhöhen. 
OLAP-Lösungen setzen vermehrt auf die In-Memory Analyse um Zugriffszeiten auf E/A zu verzichten.
Das Dateisystem ZFS bittet die Möglichkeit Arbeitsspeicher als Cache zu nutzen. \todo{ZFS erläutern}

% Hardware
\todo{Würde Hardware oben erzählen :}%, NVRAM http://en.wikipedia.org/wiki/Non-volatile_memory http://de.wikipedia.org/wiki/Phase-change_random_access_memory}
Ein direkter Weg die E/A-Leistung zu verbessern ist die Verbesserung der Hardware und hier können wir wahrscheinlich die meisten Entwicklungen sehen. Als Beispiel kann man die Entwicklung von Massenspeicher anschauen. Während der gesamten Entwicklung wurden die Drehzahlen der Festplatten erhöht, die Schreib- / Lesekopfgeschwindigkeiten verbessert, die Datendichte, die Cachegröße und die unterschiedliche Zugriffsstrategien und Optimierung der Schreib- /Lesekopfwegen angewendet. Die letzten Generationen der Festplatten wurden mit Edelgas befüllt und haben Flüssigkeitsgleitlager. Einen wesentlichen Schritt hat man mit der Einführung der SSD gemacht. 

% Busse
\todo{IDE, SATA, SAS fehlt}

% Ausnutzung der Lokalität
Leistungssteigerung ist auch direkt bei der Programmierung möglich, z.B. kann man die Lokalität der Daten ausnutzen. Wenn man genau weiß wie die Daten im Speicher abgelegt werden, dann kann man sein E/A-Befehl auf kleine Anzahl von E/A-Zugriffen optimieren. Allerdings setzt dies ein tiefes Verständnis des Systems und sehr gute Kenntnisse in einer hardwarenahen Programmiersprache voraus. In der Praxis ist diese Methode nur auf einfache Fälle anwendbar. Außerdem garantiert es nicht, dass die Optimierungen auf anderen Rechner genauso effizient laufen. Fertige Programme kann man nicht optimieren.

% Loesungsansaetze sind nicht ausreichend
Trotz allen Bemühungen verschärft sich das Problem zunehmend und stellt eine Herausforderung an die Forscher eine wirtschaftliche und leistungsfähige Lösung zu entwickeln. Zahlreiche Unternehmen und Forschungseinrichtungen haben das Problem bereits angegangen und zahlreiche Projekte gestartet, die sehr unterschiedliche Wege gehen.

% aktuelle Forschung
HP forscht an einem neuartigen Datenspeicher \cite{hp_memristor_future}, der mit Hilfe von Memristoren realisiert werden und den flüchtigen schnellen Arbeitsspeicher und den nichtflüchtigen langsamen Massenspeicher vereinheitlichen soll. Solch ein Speicher ermöglicht auch eine Computerarchitektur, in der die E/A-Problematik zumindest lokal wesentlich entschärft werden kann. Der erste Prototyp soll laut dem Zeitplan im Jahr 2017 erscheinen und im Jahr 2020 sollen die Rechner dem breiten Markt verfügbar sein. 

\todo{Das ist viel näher dran an dem was du in der Arbeit machst als der Kram oben, hier ausbauen, schau in SIOX papers, MPI hints, tuning von Dateisystemen, Problem mit der Analyse der E/A, Darshan und SIOX erwähnen...}
Eine andere interessante Forschungsrichtung ist die Optimierung der E/A-Aufrufe. In einem Zweig geht man davon aus, dass Systeme, die parametrisierten E/A-Aufrufe anbieten das Potenzial haben mit optimalen Parametern beschleunigt zu werden. Die Schwierigkeit dabei für jeden individuellen E/A-Aufruf die optimalen Parameter zu bestimmen und zu übergeben. Schafft man das, dann kann die Leistung in vielen Fällen zumindest theoretisch wesentlich verbessert werden. In einem anderen Zweig versucht man die E/A-Zugriffe so zuordnen, damit möglichst optimal auf die Hardware abgestimmt sind. Beides ist universell anwendbar, kann als Software implementiert werden und relativ kostengünstig dem breiten Publikum zur Verfügung gestellt werden.

\todo{Motivation hier rein packen nicht mit Zielen vermischen}

\todo{Das gehört alles zu Motivation nach oben, zu SIOX und Darshan, daher mal hier hin verschoben}
Wie im vorherigen Abschnitt bereits angedeutet, kommen bei der Realisierung der E/A-Systeme verschiedene Hard- und Software-Technologien zum Einsatz, z.B beim Zugriff auf die Festplatten spielt das Dateisystem, Bus, Blockgröße, diverse Caches usw. eine Rolle. Alle Komponenten stehen in einem komplexen Zusammenhang miteinander und führen zu Leistungseinbußen bei einer suboptimalen Konfiguration. Die Abstimmung der Komponenten aufeinander alleine erfordert meistens schon Expertenwissen, hinzu kommt noch Abstimmung der Komponenten auf die Nutzung, die in manchen Fällen variieren und unvorhersagbar sein kann. Eine universelle Methode oder sogar eine Software, die diese Aufgabe erleichtert, wäre hier sehr willkommen. Dazu fehlt allerdings noch die Grundlage, weil Vorgänge auf der E/A-Ebene wurden bisher nicht ausreichend untersucht sind. Es fehlt Wissen über die Zugriffsmuster, die bei der komplexen Nutzung entstehen, deren Ursachen und Auswirkungen auf die Systemleistung. Dementsprechend fehlen auch 
Gegenmaßnahmen zur Vermeidung von unerwünschten Situationen.

\subsection{Ziele und Vorgehensweise}

\todo{Das ausbauen und klarer darstellen. Ein bis zwei Satze was du machst und was das bringt, dannach die Teilziele klar darstellen }
Eine einfache und gleichzeitig effektive Methode könnte die Parameteroptimierung bei parametrisierbaren E/A-Zugriffen sein. 
Der Gedanke geht davon aus, dass die an die aktuelle Situation dynamisch angepasste Parameter bei manchen Systemen zur einer wesentlich besseren Leistung führen können, als die statisch festgelegten Werte. Das Ziel wäre dann solch eine Methode zu entwickeln und zu untersuchen.

% messen und verstehen
% Programm Verhalten
% Machine Learning
% Rule Extraction

%\subsection{Aufgabenstellung}
%%% Vorgehensweise: Potezial pruefen, Potenzial nutzen, Wissen ableiten %%%
% Werkzeuge: Machine Learning, SIOX

\todo{Das ist noch etwas unkonkret}
Diese Arbeit soll ein Blick hinter die Kulissen auf der E/A-Ebene werfen und einige Parameter identifizieren, die ein Einfluss auf die Systemleistung haben. Dann soll geprüft werden, inwieweit die Parameteroptimierung eine Leistungsverbesserung hervorrufen kann und das Potenzial bestimmt werden. Schließlich soll eine Methode zur systematischen Analyse und Optimierung mit Hilfe von Machine-Learning-Algorithmen entwickelt werden. 

%Zum Erfassen von E/A-Zugriffen wird SIOX verwendet werden, ein Tool fängt alle Systemaufrufe vom Programm ab und stellt sie für die Analyse zur Verfügung. Die Datenmenge soll auf Anomalien und Strukturen untersucht werden. Die Ursache für die Entstehung der Anomalien und die Strukturbildung soll erklärt werden.

\subsection{Aufbau der Arbeit}
% Verwandte Arbeiten: 6 Stueck
% Theorie:
	% Begriffe: aus Machine-Learning, zur Leistungsbeschreibung
	% Techniken: Arbeitsweise von Cache, Festplattenmechanik, Betriebsysteme
	% Datenfluss: Speicher -> Cache -> Verarbeitung, Leistungsverluste
	% Werkzeuge: SIOX, Machine-Learning
% Implementierung: Predictor, Classificator, Rule Extraction
% Auswertung: 
% Schlussworte
\todo{Am Ende nochmal überarbeiten}
Das zweite Kapitel stellt einige verwandte Arbeiten aus dem Bereich der E/A-Zugriffsoptimierung vor. Im dritten Kapitel werden die theoretischen Aspekte behandelt. Dort werden die relevanten Begriffe definiert, die Funktionsweise der aktuellen Technologie erläutert und die benutzten Werkzeuge vorgestellt. 
\todo{Den Satz kann man so nicht schreiben, besser das Design usw... :-)}
Im vierten Kapitel befindet sich die Beschreibung der eigentlicher Arbeit, die im Rahmen dieser Thesis behandelt werden soll. 
Im fünften Kapitel wird die Umsetzung vorgestellt und die Ergebnisse ausgewertet. Zum Schluss gibt es noch eine Zusammenfassung und den Ausblick auf weitere Forschungsmöglichkeiten.
